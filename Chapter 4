4. Classification

Classification은 regression과는 달리, 반응변수 Y가 qualitative 즉, 질적인 자료일 때 사용하는 방법이다. 
관측값을 특정한 class나 category로 분류하는 작업이다. 이 때, 분류가 될 때에는 확률을 통해서 ‘예측’하기 때문에, regression 기법과 비슷한 특성이 있다.
우리는 이 책에서는 3개의 classifier을 다룰 것이다; logistic ‘regression’, linear discriminant analysis, K-nearest neighbors.

4.1 An Overview of Classification
balance(카드대금), income(소득)이라는 설명변수들을 통해 default(신용불량) 여부를 알아내는 예시이다. 
소득은 큰 상관관계가 없고, 대체로 balance가 많을수록 default가 yes로 나타났다.

4.2 Why Not Linear Regression?
그렇다면 왜 Linear Regression에서는 반응변수 Y가 질적변수일 때는 적합하지 않은가? 
예를 들어, stroke일 때는 1, drug overdose일 때는 2, epileptic seizure일 때는 3이라고 해보자. 
그러나 각각의 변수들을 수치화해서 표현했을 때, 이들간의 관계는 수치화될 수 없다. 
왜냐하면, 단계적인, 또는 계층적인 관계를 갖지 않기 때문이다. 또한, 최소제곱법(least square)을 사용하여, 
회귀분석을 하면, 설명변수에 따라 확률값이 음수가 될 수도 있기 때문에, 질적변수로 회귀분석을 하는 것은 적절하지 않다. 
물론, 질적변수를 이용해서 회귀분석을 할 수 있다. Binary변수일 경우에는 0과 1을 놓고, 0.5를 기준으로 0 또는 1 중 
어디에 더 가까운 지 ‘해석’할 수 있다. 이렇게 숫자로 질적변수를 바꾸는 것을 ‘더미(dummy)화’라고 한다. 
이처럼 Binary변수로 회귀를 하는 것은 후에 이야기할 LDA(Linear Discriminant Analysis)와 같다.

4.3 Logistic Regression
이전의 default 자료에서 예를들어, 설명변수가 balance일 때, default가 yes일 확률은
Pr(default = yes | balance)
위와 같은 조건부확률로 표현될 수 있다. 위의 확률을 p(balance)로 줄여서 표현한다고 할 때, p(balance) > 0.5 인 것을 
default가 yes라고 예측할 수도 있고, 보수적인 집단에서는 p(balance) > 0.1을 default = yes라고 예측할 수 있다. 
즉, 확률에 있어서의 그 기준점은 임의로 설정해서 해석할 수 있다.

4.3.1 The Logistic Model
p(X)의 함수를 선형회귀와 같은 식으로 한다면, X의 값에 따라, 0과 1사이에 없는 상황을 초래할 수 있다. 
X의 값이 크면, 확률값이 1을 초과할 수 있고, X의 값이 지나치게 작으면, 확률값이 음수가 나올 수 있다는 것이다. 
그러나 확률의 값은 항상 0이상 1이하이기 때문에, 우리는 X의 값에 어떤 값이 들어가더라도 항상 그 output은 
0과 1사이에 있는 값이 나오도록 하는 함수를 써야한다. 
로지스틱 회귀에서는 이 함수를 로지스틱 함수(logistic function)이라고 한다.
